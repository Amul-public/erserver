Course Overview
Course Overview
Hi everyone! I'm Jim Weaver for Pluralsight. In the course of my career, I've met my fair share of ugly, hard-to-test code. Such code's tough to work with, and being responsible for a whole code base of untested code can be challenging and intimidating. In this course, Unit Testing Legacy Code with Java, we're going to face just such a challenge together. We'll be asked to maintain a Java application that provides services to a hospital's emergency room operations. This business critical code base isn't particularly well written. And there isn't an automated test of any kind in sight. But our customer has pressing changes that need to be made. During this course, we'll learn a variety of techniques to tackle the biggest part of the legacy code problem, breaking dependencies between units of code that make testing difficult. The techniques we'll learn will allow us to get code under test with small, targeted conservative changes that don't disrupt other parts of the system. We won't be telling our customer to wait while we rewrite parts from scratch. We'll also learn techniques to improve the clarity of hard-to-understand code with low-risk changes until we can get a test in place, and we'll see how higher level tests can help improve our safety net as we gradually get code unit testable. By the end of this course, you'll have learned a toolkit's worth of techniques that will help you tackle untested legacy code bases. So come join me for unit testing legacy code in Java.

Introducing Our Legacy System
Module Overview
Hi! This is Jim Weaver for Pluralsight, and this course is Unit Testing Legacy Code in Java. In this introductory module, we'll discuss several definitions of legacy code and why tests are important to get in place for a legacy system. We'll get an introduction to the legacy system we're being asked to modify, which will serve as our example system throughout the course. And most importantly, we'll discuss our strategy for maintaining and modifying our legacy system without breaking it so badly that we lose our jobs.

Legacy Code as Untested Code
So what exactly is legacy code? If you've been a developer for any length of time, you've probably heard the term and may very well have had to maintain or support a system referred to by your teammates or coworkers as a legacy system. The most likely definition to find in a dictionary would simply be a system that's no longer supported at all. There are no new features being developed and no PATCH releases for bugs either. For the purposes of this course, we are being asked to modify a system, so this isn't the definition we're using. We might also hear a very old system referred to as legacy code. Maybe the code was written in an outdated language or an old style or no longer uses current technologies or libraries. While this definition is commonly used as well, it's also not what we'll use for this course. Our sample legacy system will be using technology still relatively current and in use. Probably the most common definition of legacy code would be code that's just poorly written. It's very hard to understand, and when you make changes, they often result in bugs. The code may be tangled. Changing it in one place causes it to break in another unexpectedly. No one really wants to touch this kind of code. This definition of legacy code is much closer to what we'll use in this course, and our sample system's going to have some sloppy code. But the definition still isn't perfect. The last definition you might hear for legacy code is just code someone else wrote. We're not familiar with the code, it's kind of suspicious, and probably the person who wrote it didn't know what they were doing, at least that's our opinion. Well, I've heard this definition as well. It's also one we're discarding for now. We're going to consider legacy code simply as untested code, code with no unit tests or other automated tests supporting it. This definition was put forward by Michael Feathers in his 2005 book, Working Effectively with Legacy Code. His contention in this work is that code without tests is simply bad code. If it's well written, clean, and pretty, but it doesn't have any tests, it's still bad code. Now this is a very controversial statement. But Michael justified it reasonably well. If there are no tests, you can't be sure when you're modifying the code that you haven't broken something. The more significant the changes, the more exponentially risky they are. Unless it's a very small system that you know like the back of your hand, you can't modify it with any confidence. This means you have to proceed very cautiously and slowly. You may need to run the application and test it manually repeatedly with each small change. Basically, an untested system is difficult to change with either speed or confidence, so considering such a system legacy seems very defensible. And this is the situation that we'll face in this course--an untested system that we need to modify. And that brings us to a dilemma which Feathers refers to as the legacy code dilemma. When we change code, we should have tests in place, but to put tests in place, we often have to change code. This is because code that wasn't written with automated tests in the first place is often difficult to apply tests to. And we'll see repeated examples of this with ERServer in this course.

Our Legacy System
Let's get an overview of the legacy system we're being asked to support for this course. It's called ERServer, and it's a server-side API to support a hospital's emergency room operations. There may be multiple clients that rely on this server-side system-- dedicated clients on desktops, web frontends, and even smartphone apps. But our responsibility is just the back-end, server-side part of the system. Unfortunately, we've learned that there are no automated regression tests of any kind for this system, including unit tests. There's no safety net to tell us if we've broken things when we modify the code, and we don't fully understand all of the code in the system or the details of all the functionality provided. This isn't an uncommon situation to find yourself in over the course of your career. On top of that, our customer has changes they'd like us to make. We can't just freeze this code base and start writing a new one from scratch. So we're faced with the legacy code dilemma--we want tests to reduce risk of modifying this system, but the code may not be testable without modification. So let's talk about ERServer in a bit more detail. The code for ERServer, as well as some test examples we'll go through in the next module, are available on GitHub. You don't need to go grab this now, but if you want to work along on your own as we learn techniques during this course, we'll get you set up for that in the next module. We do understand some high-level facts about ERServer now though. The code is not written in a ridiculously old language. It's in Java 8. It uses Maven to build, which is a fairly common, widely-used build tool for Java apps. And the interaction between the server-side part of the application and its client applications is over HTTP with JSON for the data format. The HTTP request and response handling is managed by a Java library called Spark Java. So we aren't dealing with little-used or badly outdated technologies, just a lack of tests. In terms of high-level functionality, the system tracks patients who are inbound to the emergency room. Obviously, having advanced notice of patients in route to the emergency room and how critical their condition may be is important. A second responsibility for the system is managing and tracking emergency room resources--what beds are currently available? What staff members are available? How are staff and beds currently assigned to patients? All of this is ERServer's job to keep up with. Finally, a key responsibility for the system is alerting for critical situations. ERServer may need to let staff know if something's happened that requires their attention via paging, and it may need to let external agencies know who are transporting patients to the emergency room if the ER becomes overloaded and the patient should be diverted to another hospital's emergency room. It's clear that this application provides absolutely critical services upon which lives could hang in the balance, and yet we have no tests to rely on to make sure those functions remain working as we modify the system. We need a plan.

Testing Previously Untested Code
So let's talk about how we're going to handle our responsibility to maintain and enhance ERServer. How are we going to test previously untested code and gradually establish a safety net for modification? To begin with, we're going to take a look at different types of tests we can leverage and establish some terminology for these tests. Ultimately, this course is focused on unit testing techniques. But with the legacy system, there are other types of tests that could also be beneficial to get in place early, so we'll take a look at these in module 2 along with how they fit into an overall testing strategy for a system. Next, we'll learn a number of techniques to get code with problematic dependencies under test. Dependencies between different parts of a code base or dependencies on external systems are the single greatest challenge to getting any type of tests in place for a system. Learning how to deal with dependencies to allow testing is one of the most important things software developers can learn. We'll focus on dependency-breaking techniques in module 3. The next part of our puzzle is learning techniques to get hard-to-understand code under test. Code that is tangled, overly long, or hard to read is also hard to test. So we'll learn some techniques to get such code under test in module 4. A final part of our strategy throughout is to be conservative. We don't want to rewrite parts of the system even using test-driven development to get it under test. That's simply too risky. We'd have no way of being sure that we preserved the prior functionality. We want to make the smallest possible changes that allow testing. Some of these techniques that we'll apply are not going to make the code prettier. That's not our point. If a technique temporarily makes the code a little bit uglier but allows that code to be tested, that's wonderful. When we have code safely under test, then we can clean it up. Let's briefly talk about where the techniques you'll learn in this class come from. Many of the techniques originate from Michael Feathers' book, Working Effectively with Legacy Code, which we referenced earlier. This work actually draws some from Martin Fowler's earlier work, Refactoring: Improving the Design of Existing Code. And we'll learn some techniques from this work as well, which was so influential that almost every modern code editor provides automated options to provide refactoring operations described in the book. Finally, we'll refer to techniques and principles put forward by Bob Martin in his book, Clean Code. These are all works you should read, and we'll discuss some additional sources and other Pluralsight courses in module 5.

Module Summary
Hopefully, this module has put into context everything we're about to learn. We've established our definition of legacy code as code without any tests. We understand that we need tests to provide a safety net to allow us to change code with a minimal chance of creating bugs and to be able to quickly change code with confidence. We were introduced to ERServer, a highly critical and completely untested application that we're going to be responsible for and that we'll be working to get parts of under test throughout this course. And, finally, we have a high-level idea of the types of techniques we're going to be learning and applying to get that code under test. In the next module, we'll demonstrate several different types of tests that can help us. Then we'll dive into the techniques themselves.

Understanding the Role of Different Types of Tests
Module Overview
Before we begin wrestling with code, it's a good idea to have a strategy in mind. Understanding the different types of tests we can apply to our legacy system will help us form that strategy. In this module, we'll learn about different types of tests by granularity, audience, and purpose. We'll check out the ERServer sample project and demonstrate those different types of tests. And, finally, we'll formulate our high-level strategy for testing ERServer.

Types of Tests
It's worth pointing out before we start that terminology to describe tests has not been consistent in the industry over time. And sometimes the same term may even have had several different meanings depending on context, for example, integration test, which some would say means testing different modules of a system together, and others would say means testing your code against external systems. I'll be using terms primarily from Gerard Meszaros' book, xUnit Test Patterns. If I use a term differently than you've heard it before, don't let it distract you. How that type of test can help us is the important thing. Let's consider types of tests by granularity. In other words, the amount of code that type of test may cover. A unit test tests just a small piece of code. In an object-oriented system like Java, that's typically a single class, and an accepted form is to test through the public interface of that class. Typically when unit testing, you don't want the test to cascade through other classes. You're trying to test a class in isolation. In Java, this kind of test is typically done with JUnit, a unit testing framework. The next step up in granularity is a component test, which is a test that covers a small cluster of coupled classes usually that provide some logical service to the application. These tests are usually written with an xUnit testing framework as well, so for Java, again, JUnit. This level of test some have maintained is still a unit test, just that the unit of code is a clump of classes rather than a single class. But we'll stick with Meszaros' definition of this as a component test for this course. The next step up we'll consider in our strategy is an end-to-end test. Such tests test the entire deployed system to an entry point such as the user interface or, for a service, a service API over HTTP for example. There are specialized tools for this kind of testing, but an xUnit framework could still be used. So what about the tradeoffs between these levels of granularity? Unit tests cover a very specific small amount of code, whereas higher-level component and especially end-to-end tests cover a larger amount of code. However, unit tests can execute very quickly, and the higher-level tests will be slower, especially an end-to-end test hitting a deployed application. Unit test failures also typically point you to exactly where the problem is, whereas failures in higher-level tests can be harder to trace to a root cause. Stated another way, a single bug will often cause just a single unit test failure but potentially many higher-level test failures. Unit tests typically only need to be changed when the class they are testing changes, but higher level tests can be more brittle especially end-to-end tests. Tests at different levels of granularity are complementary to one another, but for a completely untested system, I would emphasize getting unit tests in place as you need to modify code or to address particular risk areas. Another perspective from which to consider tests is who writes, maintains, and views them. Technically-facing tests are authored and maintained by developers, and primarily developers run them and address any failures. Unit tests, component tests, and end-to-end tests all tend to be technically facing. Business-facing tests, on the other hand, are primarily authored, maintained, and viewed by customers or domain experts. Acceptance tests are often at the same level of granularity as a component test, but the test scenarios are in a tool easy for business people to use rather than an xUnit framework. We'll see a demo of such a tool in just a few minutes. As a developer tasked with maintaining a legacy system, we may or may not have a customer to help us define a test. Also, business-facing tests tend to cut across a wider area of the code base, and the code we have at the moment is not going to be put under test easily. For that reason, again, we'll focus on technically-facing unit tests first. However, as we encounter critical business logic in our system and manage to get it under test, exposing that logic to customers and domain experts via acceptance tests is another layer we can add to our testing strategy. Let's next consider tests from the perspective of why they're written, their purpose, which in this case also corresponds to when they're written. Specification tests express what code that's not yet written should do. After the code is written, these tests provide a safety net for that functionality. They act as regression tests, but their original purpose is as a kind of requirement specification. Acceptance tests, for example, are often written before the code exists, and if you're practicing test-driven development, you're also writing unit test code ahead of the code under test in small cycles. Characteristic tests, on the other hand, test what the code already does. These are written after the code under test already exists. ERServer has no test, so we're definitely going to be writing characteristic tests. We aren't going to guess what the code should do as we get it under test. We're just going to focus on its current behavior. If we're adding entirely new code to ERServer rather than modifying existing code, we could practice test-driven development for those parts. So now let's get the sample code for this code checked out and demonstrate some of these types of tests. Then we'll sum up our testing strategy.

Demo: Cloning and Building ERServer
In this demo, we'll download the sample code for the course including ERServer from GitHub, and we'll build the code and run the application. If you don't plan to work along with the exercises, feel free to skip this demo. You can always come back to this clip if you decide you want to try some of the techniques we'll cover yourself. Here we are on GitHub at the project page for ERServer, and there is a README here, a markdown file that shows instructions to get things downloaded and running, but we'll step through this ourselves. Note that you do need at least Java 8 on your machine, a Git client, and Maven 3. There's a link here to Apache. org to download and install Maven if you don't have it already. We can clone or fork and clone this repository to get it on our machine. Cloning will put the code on your machine, but you won't be able to commit any changes you make back to GitHub since you'll have cloned my repository. If you fork first, you'll create your own copy of the repository on GitHub, and then you can clone that down to your machine and commit changes as you work back to that copy of the repository. So let's copy this URL, and we'll go to the command line. I'm already in the directory I want to clone down to, so I'll enter the git clone command with the URL I copied. And, there, it's downloaded the repository. Let's step into this repository, and I can compile and test it with Maven from the command line. There we go. ERServer does not have unit tests. It's a legacy system, but there are some separate sample tests included in the code base that we're about to look at, and those are the tests that just ran. So that's it. We have our copy on our machine. And you can open it in your favorite IDE when you want. I'll be using IntelliJ for the remainder of this course.

Demo: Unit Test
In this demo, we'll take a look at a unit test, a test of a single Java class in isolation. Here we are in IntelliJ with a project open for the code we cloned from GitHub. We'll navigate to a class called ChildClassification. And this class is actually a Java enumeration, and it looks like it has responsibility for categorizing a child based on their birthdate and the current date. A child less than 30 days old is considered a neonate. Between 30 days inclusively but less than 2 years old and they're considered an infant. From 2 years to less than 12, they're considered a child. And from 12 to less than 16, an adolescent. Once they hit 16, that's it. They're undefined. Not a child I guess is what that means. There's also a return of UNDEFINED at the end here. That code probably can't be reached unless maybe daysOld and yearsOld were calculated to be negative. There are lots of interesting possibilities here for such a small class and a single method. If I had no test for this logic, I would be concerned. But there is one, and I'll use an IntelliJ hotkey to navigate to it. It's called ChildClassificationTest, and this is a JUnit test. The setUp method, which we'll run before each test method executes, pins a currentDate field to January 10, 2000. Then we have a series of test methods that appear to be checking the boundary points of each of the child classifications. There's a test for the UNDEFINED case at 16 or over, and here's a test where nonsense data is passed in and negative age would result. Let's run these tests. And they currently pass. Let's go back to the class under Test, and let's see if we can clean this code a bit. It seems like at the end here, we should be able to just have an else clause and have the same behavior with a little bit less code. Let's try that. And rerun our test. And all the scenarios still pass. So you can see how this unit test provides a nice safety net for modifications to the code. Let's look at the class under Test again, and notice these dates being passed in as parameters. These are part of the Java language, but they do represent another class involved in the test. It's a type of dependency that's passed in as a parameter. It's not causing a testing problem yet, but we'll see in a moment that even an innocent language library dependency like this can create some issues as we look at some coarser-grained tests.

Demo: Component Test
Let's take a look at a component test, a test for a small group of classes that work together to provide a logical service within the application. Here we are in IntelliJ again, and let's open a class called DosingCalculator. There's a single method here, and it looks like it's intended to provide recommendation for a single dose amount of a given medication for a given patient. The work doesn't look like it's really being done here though. An instance of a DosingSource class for the patient and medication is obtained. And then that dosingSource is asked to provide a single dose value based on the medication and child classification of the patient. DosingSourceFactory looks like it currently only returns an instance of a ChildDosingDatabase. So let's look at that. That class looks like it's essentially an in-memory database that provides recommended single dose values based on the medication and classification. So we have a number of classes involved here to calculate a recommended dose. But DosingCalculator is the entry point into all of this logic and class interactions that provide this feature to the application. Let's have a look at a JUnit test for the Dosing Calculator. It sets up a calculator instance and patient for each test and then has a series of tests to see if a correct dose is returned given the medication string and patients with various child classifications. Let's run it. They all pass. IntelliJ can show us coverage data for what classes and lines of code are exercised by tests. Let's enable that and run these tests again. We can see five classes were touched during execution. So this looks like a useful service to test, and we got a good amount of test coverage. So what's the downside? Well, we pulled in more dependencies. Imagine if the dosing source were a physical database. This test would run slower, and if meds in the database changed, say due to a vendor updating drugs, tests could fail when the logic is really still correct. Also, let's look at the dosingCalculator test again. And notice how age is having to be calculated for these scenarios. The birthdate of the patient is being back-calculated from when the test is run. In the ChildClassification unit test that we looked at a moment ago, we were able to pass in a specific date to be considered the current date. But in this wider-grained test, we're stuck with the system current date when the test is run. That's because the patient class has a getChildClassification method that's accessing the system date directly. We have no way to pass it in testing at the dosingCalculator level. So is that really a problem? Well now this is a dependency that could cause a testing issue. Let's flip back to the test. Notice this first test scenario is back-calculating the birthdate of the patient by one month. And it's expecting a neonate dose back. If you ran this test on January 31, for example, it would fail. One month back would be December 31, and that would mean 31 days, and that would be an infant dose. To control these scenarios, we'd really like to be able to pass in both a current date and a birthdate like we did with the ChildClassification unit test, but we can't as the code is currently written. So the service level component tests are very useful, and they let us test whole features in a way. But the wider net they cast may pull in more testing issues that we have to deal with. After we've learned some dependency-breaking techniques at the unit testing level, we'll come back to this example.

Demo: Acceptance Test
Now let's see what value an acceptance test could have in our testing strategy for a legacy application. We'll be running a tool called Fitnesse to demonstrate this, and it's already present in the project on GitHub. Let's go to the command line, and I'll do that in IntelliJ, and let's step in to a directory in our project named Fitnesse. There's a jar file here to launch Fitnesse, and all we need to do is execute that with Java and specify a port number for Fitnesse to use. It looks like it started, so let's go to our web browser and access it at localhost, port 8080. There we go. Fitnesse is an open source, wiki-based tool that's been around a long time, and its strength is how accessible it makes tests to non-developers. We have a wiki link here to ErServerTests. And our test example for a dose calculator is here even though technically that calculation isn't part of ERServer. At the bottom of this page, though, notice the path to which Maven compiles classes from our source code. This is how Fitnesse will gain access to our source code to execute it. There's a setup page here too much like a JUnit setup method, and it just says import statements for packages needed for the tests on this page. There's only the dose calculation test here now, so let's drill down to that. And here we see basically the same calculator test scenarios that we saw a moment ago in JUnit. In this case, though, the input data for each scenario and the expected results are in a tabular format on a wiki away from any code. And because there's no programming language syntax mixed in here, it's very easy to read the business scenarios being described. Notice we're still having to back-calculate the birthdate from the current date when the test is run though. This acceptance test is testing the exact same code at the same level as we just did in JUnit, so we still have the data dependency problem. Let's run this test. There's a Test button here at the top of the page, and it executes, and the green shows us all the scenarios that passed except for a problematic one, which is the one-month one we were discussing previously. On this test, I expected infant for a one-month old but got back neonate just to show this type of failure. A customer can edit this page and modify scenarios or add additional ones. Let's briefly look at how this is wired to the code. Here on the top row of the test table, this dose calculation by med and age string is what binds this test table to a test fixture class in the source code. And it allows it to input these scenarios to the DoseCalculator component and get back results that are then compared by Fitnesse to what's on the page. Let's flip back to IntelliJ and pull up that class. We can see that it takes two inputs from the wiki test page--age and medication--and there's an execute method. This is a method that Fitnesse will call for every row that was in the test table after the input variables are bound but before these dose and childClassification output methods are called. Execute is going through some hoops to back-calculate the birthdate from the current date. If we could just input two dates on the Fitnesse page, the test would be more precise and clear, and we could get rid of about 10 lines of test bridge code or fixture code. A good acceptance test bridge class has a very small amount of code, smaller than a JUnit test, because the test scenario inputs and the expected outputs are all in the acceptance test tool, in this case a wiki, not in the JUnit test. The bridging code just needs to call the code under test from the input and return the outputs. So this is a useful parallel to a component test if we have logic we want to expose to a customer. But because of the larger granularity from a unit test, we're more likely to run into issues getting that code under test.

Demo: End-end Test
For our final test demonstration, we'll execute an end-to-end test against one of the API calls in ERServer. We'll use a tool called Postman. And this isn't included in the Git repo for the course, but if you want to try it, you can download it at the URL shown. First, let's start up ERServer through our IDE. We'll look at ERServer's code more in the next module. But for now, just to start it up on our local box, we need to go to a class called ERStubSystem and run it as a Java main. This class represents a patient transport system that's external to ERServer that informs our hospital of patients being transported to the hospital currently. That looks like it started up on a port. Now let's go to a class called ERServerRunner and start that. There we go. Now ERServer API is up and running on port 8088. Now let's run a test from Postman. Here we are in Postman, and I have a test folder called ERServer API Tests. And that has a test check that the API returns inbound patients to clients. We can see that this test is hitting the API at port 8088 via an HTTP GET request on an inbound patient's resource name. If I look at the Tests tab, it expects an HTTP status of 200 to be returned and a single patient with the name of John Doe to be returned. Let's run it. We can see the JSON that came back. It's a single patient with the name, priority, and transport ID. On the Test Results tab, we see that the test assertions both passed. So that's neat. We just ran a test against a feature of our entire application deployed on our box. But the downside's pretty obvious. What if the emergency response service we connected to returned different patients the next time? Our test would fail even though our code's still working. The dependency on that external system will probably give us trouble. Also since we're testing through HTTP against a deployed application, performance eventually will be an issue if we build up too many of these kinds of tests. Finally, if there's a failure here, what's the reason? I'd have to go digging. The cause might not be obvious, and there are several layers of code and technologies supporting this feature. On the other hand, once we've broken some dependencies and have some unit tests on ERServer, a thin layer of end-to-end tests like this could be very useful as smoke tests to ensure the whole system's behaving as expected when deployed.

Testing Strategy for ERServer
We've seen examples of several different types of test and discussed some of the pros and cons. Let's state what our strategy's going to be to tackle ERServer. First, we'll emphasize getting unit tests in place on existing code either as we modify it or, if we have time, focused on any risk areas we discover. We'll focus on characteristic tests. We'll test what the code current does. But if we find anything questionable, we can always raise it to the customers. For entirely new code, we can create specification tests as we go if we like. As we get code testable, if we discover a business component in the code, we can add higher-level tests for those and expose how those components are working to customers via acceptance tests. Finally, we can add end-to-end tests to check overall system configuration and deployment success as we're able to control dependencies better through techniques we'll learn in this course. That's our plan, and now we need to learn those techniques.

Module Summary
In this module, we learned about a number of different types of tests and saw some of those tests in action. In the process, we encountered an example of a dependency causing testing to be more difficult through just a simple reference to a Java date class returning the current system date. We've stated a high-level strategy for dealing with our legacy system. Our emphasis will be on unit testing existing code as we need to modify it, which should allow us to add higher-level tests in the future once enough of the code is testable. In the next module, we start to dig in on the techniques that will help us do just that.

Testing Code with Problematic Dependencies
Module Overview
Now that we have a high-level strategy in mind to tackle getting tests in place for our legacy system, we need to learn how to deal with our biggest challenge--dependencies between units of code that make testing difficult. In this module, we'll learn about different types of test doubles and their use and how test doubles can be provided to the code under test through the application of dependency injection. Then we'll learn a number of techniques to break dependencies allowing us to avoid them while testing or provide test doubles. We'll apply these techniques while adding functionality to ERServer, our legacy system. So while adding functionality our customer wants, we'll also be creating a test safety net to help us avoid breaking existing functionality and increase our ability to confidently refactor code in the future.

The Dependencies Problem
We saw one dependency problem in the previous module while testing the dosing calculator. Dependency problems follow a general pattern. We have some code in our system that we'd like to write a test for. That code acts as a dependency of some kind. It could be an instance of another class, and that class could be a class in our system, a class in a third-party library, or even a language library class. The dependency could also be a static method call to another class or even just a call to a different method within the same class as we're trying to test. Whatever the nature of the dependency, it makes things difficult to test. Perhaps exceptions are thrown because of the dependency, or the dependency causes our test to be nondeterministic. We can't ensure that the test will get the same results each time it's run even if the system hasn't changed. In the previous module when we were looking at the test for the dosing calculator, the dependency we observed was a static method call to LocalDate, a Java language class from the code we were trying to test. This call didn't cause exceptions to be thrown, and it didn't even make it impossible for us to write or execute a unit test against the code. But it did make the test scenario potentially nondeterministic or at least less representative of requirements. We'd like to have been able to specify that from February 28 to March 28, a child would be considered a neonate and get a neonate dose but from March 30 to April 30, for example, would receive an infant dose. Because the code we were trying to test was accessing the current system date directly via that static method call, we were unable to specify scenarios with that kind of precision. Dependencies that cause testing problems are very common and come in many forms.

Understanding Test Doubles
One of the most common ways to tackle a dependency problem is to provide a substitute for the dependency that you can control. In his book, xUnit Test Patterns, Gerard Meszaros referred to these as test doubles. So we have code that we're accessing from a test, and that code relies on a problematic dependency. The test creates a test double and substitutes that double for the real dependency. The double responds the way you want it to for that test scenario. To provide the code under test with the double, some form of seam or hook point is needed in the code under test. Basically, you need to be able to pass in the double. There are a number of different types of test doubles, and terminology for doubles has not been consistent over the years. We'll stick with Meszaros' terminology and just discuss the major category of doubles. First is the fake. This is an alternative implementation of the real dependency. For the most part, it's fully functional. For instance, if the dependency were a data access object that runs a data query language like SQL against a database to insert, update, or delete employees. A fake for that might keep employees in an in-memory data structure like a list or a map and respond to exactly the same insert, delete, and update methods by modifying that data structure in memory. Except for not saving things in a database, it's really a fully functional substitute for the real thing. Next is the stub, and this is the one I find myself using by far the most often. A stub is a double that you program to respond the way you want it to just for the specific scenario you're testing. It's in no way a fully functional substitute like a fake. The last major category of test double is the mock. This is a double that records the calls the code under test makes to it including the arguments passed, and it will fail the test if those calls don't match what was expected. Expectations can be set on a mock ahead of executing the code under test. Mocks are a little confusing to use, and I usually only use them when I'm trying to verify that the code being tested calls some external API or service correctly according to some contract. We'll use all three of these types of test doubles in this module.

Understanding Dependency Injection
Dependency injection is a core programming technique that will help us provide test doubles to the code under test. Here we see an example of some code that contains a problematic dependency. We have a SaleNotifier class used to let a store's customers know about upcoming sales. And when the SaleNotifier is constructed, there's a dependency on an emailNotifier class. An instance of an EmailNotifier is created inside the constructor. In the notify method, there's some logic we'd like to test that determines which if any offers a particular subscriber should be notified of. But it calls out to the emailNotifier when it identifies a notification situation, and that class tries to send an SMTP email message, which needs an email server, and that blows up our test. This is a classic dependency problem and ripe for dependency injection. Here we have the same code but set up now for dependency injection. The constructor for the SaleNotifier now does not create an instance of an emailNotifier class in the body of the constructor method. Instead, a notifier argument is passed into the constructor from calling code. Notifier's an interface, which the emailNotifier class will now implement. Production code can pass in the emailNotifier, and a unit test can pass in a test double that implements the same notifier interface. We pushed creation of the emailNotifier out to some other class. The notify method calls notify on the interface, which will trigger an email when used in production but a callout to a test double when in the test allowing that test to check and see what notifications were sent for that scenario. This is an essential technique to learn, and many of the legacy code techniques we'll learn and apply in this module are basically techniques that set the code up for dependency injection to be applied.

Dependency Breaking Techniques
Now we're ready to start a series of demonstrations of dependency-breaking techniques. These techniques will all be demonstrated in the context of making a feature addition to our legacy application ERServer. We'll first locate the code that we need to change to add the feature. We'll start to write a test for that functionality at the change point, but we'll run into a dependency problem. Then we'll apply our particular technique to either avoid the dependency altogether or allow us to supply a test double implementation of that dependency. Then we'll complete our test, which will be a characteristic test. It'll confirm the prior functionality of the code before it's modified to add the particular feature. Then we'll modify the code at the change point to add the functionality needed for the feature and update the test to include the new behavior, as well as the old behavior, and run the test again. In some cases, we'll demonstrate different techniques on the same change point to get around the dependency problem, and we'll even see how to combine a few of the techniques. The source code for this is on GitHub at the URL shown if you want to try the techniques yourself after each demo. In some cases, we'll use the same unit test after it's written for different demos and techniques, so keep your unit tests around as you move along through the various demos. Alright, let's get to work.

Demo: Pass Null
The first technique we'll learn is the dependency avoidance technique, pass null. Rather than passing in a test double for a dependency of a class we're trying to test, we'll just pass a null in for it. This is a trick that can work if the constructor for the class you're trying to test needs a problematic dependency, but the specific code in that class you're trying to target doesn't. Let's see what feature we're trying to add to ERServer. ERServer gets information about inbound patients to our emergency room from an external system. That system sends XML to us, which we can see here. This Condition element is new, and we'd like our system to consume that element and pass it on down to our client. When we hit ERServer's API call to return inbound information to our client, we can see that there's currently no Condition property here. So let's flip into IntelliJ and see if we can find the relevant code. We know the URL for our API call to get inbound patient info, so let's search for that, and it looks like this EREndpoints class receives that HTTP Get request, so let's click through to that. And the code for that is here. And it looks like it calls out immediately to an InboundPatientController class. And that comes from a main controller. It looks like an InboundPatientController is here, and an EmergencyResponseService is passed in to its constructor. Let's go back to the EREndpoints class and click through to the method on the controller that does the work. This looks like our change point. We can see in this method where an XML string is obtained from the external EmergencyResponseService. And then there's this block of code converting the XML returned for each inbound patient into a Patient object in our system. Our Patient object already has a Condition property. It's just not being set here yet. So let's see if we can write a test for this existing functionality with this current InboundPatients method as our test point. Let's create our test method, and let's see if we can construct an instance of the controller class. So we need to pass in an EmergencyResponseService instance to do that. Let's just try to instantiate one with the new keyword first, and we see that we need a URL, a port number, and timeout value. So for the purposes of demonstrating ERServer as a running application, we do in fact have a fake of this service in the code base. But in a real-world scenario, that doesn't exist. This is a third-party system that's available in production but not for us to connect to from a developer's box or from a CI server. So I don't have a URL to point this to. Let's just make this up and see what happens. There we go. Now let's call the method we're trying to test, and we'll assign the return value to a local variable. Let's run this before we do anymore work in the test and see what happens. As we expected, no joy for us. It blew up immediately. And it looks like it blew up in the constructor of the EmergencyResponseService class. So it looks like that class tries to go out and connect to an external service even just at the construction point. So creating an instance of EmergencyResponseService with bogus connection info in it just isn't going to work. So let's try and just pass null and run it again. And now we get a NullPointerException. Let's click through to where that exception occurred. This makes perfect sense. In the method we're trying to test, it calls the EmergencyResponseService to get the XML string. But that's null now, so we get a NullPointerException. I see a possible solution here. What if we move the declaration of this ArrayList of patients, which is what will be returned from this method under the access to the service. It's not referenced before then, so that doesn't cause any compilation issues. Now let's select this code block that populates this list of patients from XML, which is what we really want to test, and extract it into a separate method. We will call it buildPatientsFromXml. It returns an ArrayList of patients, and its input is the XML string. There we go. The IDE took care of pulling that code out into a separate method for us completely. Relying on our compiler and IDE is something we'll need to do a lot when working with untested code. Automated IDE refactoring is less likely to result in a mistake than manual changes. So now we have the method we'd like to call from our test extracted, but it's private. The test won't be able to call it. Let's make it package level for now. There we are. Now let's flip back to our test. We're still creating an instance by passing null for the service, but now let's change the test to call our new method. This needs a string for the XML. Let's supply that. This is the same format of XML that we get from the real service, and it has a Condition element in it. Now let's add some assertions on the patient returned, and we're just checking the values that the existing code returns before we add our new feature. And let's run the test. That passed. By passing null, we avoided the exception we got when trying to instantiate an instance of the EmergencyResponseService to pass in to the controller's constructor. And by extracting the XML processing code out to a package-level method, we were able to get a test in place. Now let's add an assertion for the new Condition element. And let's rerun the test. And it fails because the Condition isn't populated yet on the Patient object as we'd expect. So now let's flip back to our change point and set that value from the value of the XML node as our customer requested. And we'll go back to our test and rerun it. And it passes. If the patient is being translated to JSON for us, this feature may be added now. And we have a test in place on some XML parsing that we didn't have before. Let's flip back to Postman, and I've restarted ERServer with our code changes. So let's hit the inboundPatients endpoint, and there's the Condition value and the returned JSON. So that's the pass null technique. Usually pass null is only going to help if there's a constructor parameter that you need to pass to the class you're trying to test, and you can't create an instance of that parameter for some reason. But the specific code you need to test doesn't use that object anyway. Let's use the same feature in code to demonstrate the next technique as well.

Demo: Expose Static Method
Expose static method is a sneaky trick. And it may seem a little lazy. But it can be a low-effort way to get code under test. Basically what we're going to do with expose static method is make a method that we want to test on a class that we can't instantiate for some reason static removing the need to create an instance of that class to test that particular code. Let's return to the InboundPatientController where we just added the code to support the patient Condition property. We separated this buildPatientsFromXml method out and made it package level so we could call it. But notice this method does not use any instance variables. The only thing it operates on is the XML string passed in to it. Let's try making this method static. My IDE doesn't have any complaints about that. Let's flip back to the test we wrote in the last clip. And let's change this call to the buildPatientsFromXml method to be a static call to the class. And now notice the controller local variable is gray now because the test isn't using it anymore, so we can delete this line entirely. And let's run the test. And it passes. So originally we were having trouble creating an instance of the controller because the controller's constructor required an object, the EmergencyResponseService, that we couldn't instantiate successfully. In the last clip, we pass null for that parameter and got that to work. But with this technique, we don't even have to instantiate the class under test at all. Now this is only going to work if the method you're trying to test references no instance variables, and it may seem a little ugly to create static methods like this, but if the situation is right, it's a really easy way to get code under test and bypass difficult constructor dependencies on the target class.

Demo: Parameterize Constructor
The last two techniques we've learned avoid dependencies to get to the code we want to test. Now we're going to learn some techniques to set things up for test doubles and dependency injection. The first of these techniques we're going to learn is parameterize constructor, which can be applied when the constructor of a class we're trying to test creates a dependency that's important to our target code that we'd like to provide a test double for. This technique can be used on methods besides constructors as well. In that case, we'd call the technique parameterize method, but the basics are the same. Let's give it a try. The feature we're being asked to add to ERServer has to do with client requests to see all physicians on duty for the current shift. Here we are in Postman again, and let's hit that API call. You can see it's returning a list of doctors. What our customers want is for this API call to also return any residents that are on duty as well. Let's see if we can find the code we need to change. As we saw previously, most of the entry points for ERServer's API appear to be in this EREndpoints class. And, sure enough, there's our physiciansOnDuty call. It looks like the work is being done by a StaffAssignmentManager that we get from a main controller. Let's see what the main controller does to create the StaffAssignmentManager. It looks like it just simply constructs it, no parameters on the constructor, and keeps a static reference to it around. Let's go back and see what this getPhysiciansOnDuty call does. Here we are in the StaffAssignmentManager, and here's the code that returns physicians on duty. It looks like it loops through a collection of shiftStaff, an instance variable, and creates and returns a new array list containing all staff members with the roll of DOCTOR that are in the shiftStaff collection. So if residents are in this shiftStaff collection already, which it stands to reason they may be, then our change may just to be add a residents clause to this conditional. Let's be a little brave and just try to call this method from a test. We'll create a new test and name our test method accordingly. Now let's construct an instance of the StaffAssignmentManager and make a call to PhysiciansOnDuty. Let's just go ahead and run this. And we have a NullPointerException. Let's check through and see where it is. It's in a StaffRepository class where it's trying to access a file it looks like. And if we see where the StaffRepository was referenced, it's from the constructor of the StaffAssignmentManager. It looks like to construct the manager we need to test, there are two dependencies created in that class--StaffRepository and BedRepository. And these are basically acting like databases or data sources for real staff or beds in the production environment. And we don't really want to connect to those to test. Even if we can get a connection, it would make the test scenarios dependent on data coming from those external data sources. This looks like a pretty good job for test doubles. If we could just provide test doubles to the StaffAssignmentManager for the BedRepository and the StaffRepository, we could control our test scenario and not need to try to connect to a database or file resource. But we need to be able to pass the test doubles in. So let's create an extra parameterize constructor for this class. We'll just create a copy of the existing constructor, and let's move this bedRepo instantiation up with the one for the staffRepo. We'll see why in a minute. Now let's select the staffRepo in the new constructor, and we'll use an IDE refactoring to parameterize it. There we go. Now let's do the same to the bedRepo. That repository will likely give us trouble too, so let's set up to pass it in as well. Now my IDE is helping a lot here. It sees that I have two constructors with an identical block of code, which is why I moved that BedRepository instantiation a second ago. And the IDE is offering to call one from the other for us. Let's let the IDE to as much work as we can, so we'll say OK. That worked, but the call to the other constructor needs to be the first line. But rather than move it, let's just inline staff and bedRepo creation. Done. So we used some IDE tricks there, but we could've gotten to the same result manually. What that result is is two constructors now on the StaffAssignmentManager. One is the original constructor that production code still calls that takes no parameters, and it creates the bedRepo and the staffRepo problematic dependencies just like it did before. But there's now a new constructor that takes the bed and staffRepos as parameters. That gives us a scene to inject test doubles. Our change has no impact on other production code because we preserve the original signature of the constructor. Preserving signatures of methods and constructors is helpful when working with legacy code that we don't want to disrupt much while we're working. Now let's flip back to our tests, and we don't have test doubles yet, so let's pass null temporarily, and run our test. We get a NullPointerException when the new constructor tries to access a repo to actually get data. So we're at the right point to provide a test double. And we'll do that with the next technique, extract interface.

Demo: Extract Interface
Extract interface is a key technique for dependency breaking. You create an interface for a problematic dependency allowing you to provide a test double to the code under test that implements the same interface as the real dependency. In the previous clip, we used the parameterize constructor technique to create a seam where we can inject a test double to help us test changes to the physicians on-call functionality in ERServer. Extract interface will allow us to inject the test double at that seam. Here we are in the StaffAssignmentManagerTest where we left off in the last clip. We have our new constructor available to inject doubles for staff and bed repositories, but we can't inject a real repository. These are full of file access code. However, we can use our IDE to create an interface for these repository classes. Let's do that. And the method we want on the interface is this getShiftStaff method. And now we need to give the interface a name. That's a little tricky. If the staff repository class were named StaffFileRepository, I might use StaffRepository for the interface name. But rather than rename things in midstream here, let's just call this interface StaffProvider. Now our IDE is being super helpful. It's asking us if we want to replace appropriate places like parameter signatures where StaffRepository appears and change that type to be our new interface instead. That sounds great, so we'll say OK. And it previews what those signature changes will be for us. It looks like it'll change our new constructor to use the new interface. That's perfect, so we'll go ahead and with that. And we can see our type on the new constructor now is the interface rather than the file-based staff repository. Let's check out the interface our IDE created, and that looks right. And also it already declared that the StaffRepository class implements that interface. So our IDE paid for its keep there and saved us a lot of manual labor. Now let's quickly do the same for the BedRepository parameter. There we go. We have a constructor on StaffAssignmentManager that takes interfaces from both the repository parameters. Now we can complete our test. Let's pass in a test double for the StaffProvider, and we'll call that StaffProviderDouble. And let's let our IDE create that for us. And IntelliJ's warning us that we're about to create this class in the test root rather than the source root, and that's okay in this case since this test double class is only going to be used from unit tests. So we'll tell it to proceed. And here's our test double that we need to implement. Let's implement the interface methods first. So that gets the key method signature in place. Now let's declare an ArrayList of Staff as an instance property. And in the constructor, we'll initialize that. And then let's add a method to this test double that allows the test to add staff to the test double that should be returned for the scenario being tested. There we go. Now let's flip back to our test. And I went ahead and did the exact same thing for the BedProvider, created a double for it, but we don't need to provide any beds for this test scenario. So let's pull out the staff double as a local variable, and now let's add staff that we need for this scenario. We'll go ahead and add one doctor and one resident. Now let's add some assertions. We should get two physicians back as being on duty in this case after we make our feature change to consider residents physicians. So let's run the test, and it fails because it got one staff member back instead of two. But that's what we expected since only doctors are currently being returned from this method. Let's click through and implement our change now. There we go. Now let's go back to our test and run again. And that worked. We have a test in place on this code, and our feature change is made. Now that I have a test here, I'd probably also add some checks that other staff types like nurses don't get returned from the PhysiciansOnDuty method, and any other methods on the StaffAssignmentManager that return subsets of either staff or beds can now probably all be unit tested where they couldn't before. So we did some good here, but let's look at another way to create these test doubles. Notice we now have these two test double classes in our test source root. That's okay, but there are libraries we can use to create test doubles for us. Let's use Maven to add one. I'm going to add a Maven dependency on a library called Mockito, and we will make the scope of that dependency test, which means we can only use this library in test code, not production code. And let's go back to our unit test for the StaffAssignmentManager. I've already written a duplicate of our test method but using Mockito instead of manually created test doubles. This new test creates a local ArrayList of Staff and adds the staff we want for our test scenario to that list. We also declare an empty beds list. Then it asks Mockito to create an object on the fly that looks like a StaffProvider and the same for a BedProvider. Then we tell these two objects that Mockito creates for us to return our list whenever the mock object has the appropriate method called on it. Then we create our StaffAssignmentManager with the two Mockito-created test doubles, call the method under test, and repeat the same assertions. Let's run it. And this passes as well. So there's more code in this test to use this approach, but we didn't have to create actual classes for our test doubles. I use both these approaches in real systems. If I need a fake, something like an in-memory implementation of a database access class, I hand create them. If I just need a quick stub that'll be used in a single unit test, I use Mockito. Let's hop back to Postman and hit ERServer's PhysiciansOnDuty function to see if our feature's now working end to end. And it is. We see doctors and residents are now returning from the API. So we used a combination of parameterize constructor and extract interface techniques to allow us to dependency inject and get the code for this feature under test. On top of that, a number of other API calls use the StaffAssignmentManager, and a lot of that functionality can now be unit tested. Let's move on to a new feature and learn some new techniques.

Demo: Subclass and Override Method
The next dependency breaking technique we'll learn is subclass and override method. This isn't one I use nearly as much as extract interface, but it's quick to do, and it's sometimes the most unobtrusive way to get around a testing issue. Basically, if there's a method called from the method you're trying to test that introduces a dependency or other issue, you may be able to create a subclass of that class purely for testing and override that method to do what you want for your test. Let's give it a try. There's a feature in ERServer to send pager alerts when a new patient is detected inbound with a red priority. It's implemented here in AlertScanner. ERServerMainController starts a timer task that runs every 30 seconds that calls the scan method of the alertScanner. If we look at the console for ERServerRunner, we can see it scanning periodically. Let's hop out to Postman, and we have a post we can make to our fake emergencyTransportService to create a new inbound patient. Let's add a new priority red patient and flip back to the console, and we can see it detects that new patient and attempts to send a page. It fails, but that's because this pager system is available in our theoretical production environment for ERServer but not on our box for testing. Our customer would like us to modify this functionality such that yellow priority patients who have a specific condition, heart arrhythmia, should also cause a page. There are no tests yet for the alert scanning functionality, so we'd like to get one in place. But right away, we can see the inboundPatientController being passed in to the scanner constructor. We already know that class talks to an external system, and that will cause us a testing problem. So we already have a bag of dependency breaking techniques. Let's apply one and extract an interface for the InboundPatientController. We'll call it InboundPatientSource, and we'll put the current inbound's method that we're interested in in this informOfPatientArrival method both on the interface. BuildPatientsFromXml is one we exposed earlier to unit test XML to patient conversion, but it's not really part of the business API for the InboundPatientController. Again, IntelliJ offers to place the interface type at appropriate points, and we'll accept that. The controller implements the new interface, which has the two business operations on it. And the AlertScanner's constructor now takes that interface type. We have a seam to inject a test double for the inboundPatientController to the scanner. Let's go ahead and create a unit test for the scanner, and let's try to verify the existing functionality of a page for priority red patients. There are a couple of oopses in this test code, but we'll fix them in a minute. I've already created a test double for inbound patients. Let's look at that. And it simply returns a list of patients that our test can add to by calling this simulateNewInboundPatient method. And, of course, it implements our new interface as well making it a test double for the inboundPatientController. If the informOfPatientArrival method were implemented on this double to remove an appropriate patient from the in-memory array list probably, we'd have a good fake test double for the inboundPatientController. It'd really be a fully functional substitute for the production class, and we could use it for many other system tests. But now let's go back to the scanner. To alert on a yellow heart arrhythmia patient, our change point's going to be here. But when this alert method gets called, a real patient gets sent using these vendor library paging classes and calls. That's going to blow up our test. Here's where subclass and override method can help. Let's go back to the test tree and create a subclass of the AlertScanner from there. We'll call it the AlertScannerTestingSubclass, and we'll extend AlertScanner and provide a constructor. Now let's flip back to the real AlertScanner class and make this problematic method that sends a real page protected. Now back to our new subclass, and let's override that alerting method. Now let's add an ArrayList where the testing subclass can keep track of patients that we ask it to alert on. And on second thought, let's just make that list public so that the test can access it easily. And then we change the overridden method to add to that list when the subclass scanner is asked to perform an alert. Now back to our test, and let's fix some oopses here. This helper method to create a test patient actually needs to return that patient, and we need to call that helper method to add a red priority patient to our InboundPatientTestDouble. And now we'll change that test to use the new subclass rather than the AlertScanner directly. And let's add some assertions. With the single red priority patient inbound when this scan happens, our scanner test double should be asked to page once for a patient with that transport ID. Now it may seem odd that we're testing a non-production class here. Well that's true, but we are testing the production code that we're about to change. The AlertScanner testing subclass is all production code inherited from its parent except for the one overridden method that saves an alerted patient to a list instead of sending a real page. Let's run this test scenario, and it passes. Let's add an additional yellow priority patient to the inbounds and make sure we're still only alerting on the one red patient, and that passes. Now with the help of extract interface and subclass override method, we have a test of the existing functionality in place. Let's make the code change our customer asked for. We'll add an else clause here to alert on a yellow arrhythmia patient. And let's go back to our test and add another test scenario to verify that a yellow arrhythmia patient gets an alert. Let's change these transport IDs so they don't look like size verifications and run both these test scenarios, and they pass. Our functionality's added, and we have test coverage. Let's flip back to Postman, and we'll add a new inbound red priority patient to the yellow arrhythmia patient that the system starts up with. Now back to the console, and we can see the AlertScanner attempting to send real pages for both of those inbound patients as it should. So that's subclass and override method, and we have tests in place now for the AlertScanner, which had some problematic vendor API calls. We'll continue to work on the AlertScanner with our next technique, wrap API.

Demo: Wrap API
The next technique we'll learn is wrap API. And this is a little like the extract interface technique but in reverse. Instead of creating an interface to represent an existing dependency signature, we push some code that accesses a third-party API to a new class and then create an interface for it. You can push code other than API calls behind an interface, of course, but this technique can be especially helpful for dealing with calls to external libraries that prevent testing. Let's take a look. Here we are in the AlertScanner code again. We just added a feature in the previous clip to send a pager alert for a yellow heart arrhythmia patient. But now our customer has some changes they'd like to make to how the paging happens itself, which is going to force us to modify this alert method. We got a test in place for the scanner in the previous clip, but we did so by subclassing the scanner and overriding the alert method. So our current test covers the logic in the scan method, but we have no coverage on the alert method that has these vendor library calls in it. What our customer would like us to change is to not require an acknowledgement for a page concerning a priority yellow patient, only require an acknowledgement for priority red patients. The vendor PagerTransport class has a transmit method on it that doesn't require acknowledgement that we need to call in this situation. So this seems like we're between a rock and a hard place. We need to test how the vendor library's called, but we can't actually call the library while testing. Well, this will require some manual work, but an interface can help us. First, we have to create a class for the interface to be applied to. Let's create a new class, and we'll call it PagerSystemAlertTransmitter. Now let's copy the two method signatures from the vendor PagerTransport class that are business crucial--transmit and transmitRequiringAcknowledgement--to our new class. Now let's go back to the AlertScanner and copy the code that does the actual paging and paste that into this transmit method. Now let's replace these hardcoded values with the parameters, and let's copy the same code to the transmit without acknowledgement method, and let's extract some common code here. And we need to change that API call to just transmit, but let's go ahead and extract an interface now. And the interface we'll call just AlertTransmitter. Now let's fix this API call. Here's our new interface, and we have an implementation that calls the real vendor system. Let's go back to the AlertScanner now and start to make some changes. Let's add an instance property of type AlertTransmitter, our new interface. And in the existing constructor, we'll assign that to an instance of the pager system, alertTransmitter, the implementation of the interface that wraps the actual vendor API calls. Now let's scroll down to the alert method and use that new property to accomplish the alerting. And then we can delete the old API calls. Now let's give ourselves a seam to inject a test double for the AlertTransmitter. Let's add a new constructor that takes both an InboundPatientSource and an AlertTransmitter. We'll just call this constructor from test for now. And let's call the new constructor from the old one. Now back to our unit test for the AlertScanner. Before we implement our new feature, let's get this test green, and it still passes. But, of course, it's using our previous testing subclass that doesn't have a real alert method. Let's change this scenario to create a test double for an AlertTransmitter. And that test double is just going to hang on to alerts it receives as strings that we can validate. And we'll keep separate alerts requiring acknowledgement and those that don't. And let's add a getter for those lists so our test can verify what alerts were sent from the scanner. And back to our test, now we can remove the reference to the testing scanner subclass and just use the AlertScanner class directly. And we'll call the new constructor that takes an inbound patient source and a transmitter implementation, both of which we're providing test doubles for. Now let's change the assertions on the alerts received to use the exposed properties on our transmitter test double. Let's give it a try. Oops, we've got a NullPointerException in the AlertScanner. Let's check that out. This list of patients already alerted on that the scanner keeps, I messed up ensuring is initialized regardless of which constructor gets called. Let's fix that and rerun. That still fails. This time, it looks like it didn't see an alert it expected. Let's check the test scenario again. I'm checking the list of pages not requiring acknowledgement, and this scenario with a red priority patient does require acknowledgement. Let's clean this assertion up a bit, still failing. Let's fix our assertion, and it passes. Now let's modify the second test scenario. But here we'll verify that a transmit alert is received rather than transmit with acknowledgement. And that fails, but that's because we haven't implemented our feature change yet. Let's go to the AlertScanner and do that. We'll simply add a conditional so that we transmitRequiringAcknowledgement only for priority red patients. Now let's rerun the new scenario test, and that passes. Let's rerun both scenarios, and they both pass. Now we can also add a new scenario to verify that repeated scans don't cause multiple alerts on the same patient, and that passes as well. So that feature change is implemented, and with our unit test now able to use a test double for the actual vendor paging, we can get more detailed tests on paging functionality in place.

Demo: Revisiting the Dosing Calculator Test Problem
In the previous module, we ran into a dependency issue on the Java local date class when trying to write a high-level component test for a pediatric dosing calculator. Now that we're equipped with a toolbox full of dependency breaking techniques, let's see if we can resolve that issue. So here we are in the DosingCalculatorTest, and let's run it again. And the first scenario's failing at the moment because of the time of year when I'm running the test. It's that current system date dependency biting us again. Let's find that dependency. It wasn't here in the DosingCalculator itself, but it's down here in the patient getChildClassification method. Rather than redesign this code significantly, let's use a bonus technique--extract getter. Let's pull this call to LocalDate. now out to a getter method. And we'll call it getSystemCurrentDate. Now that we have this dependency returned from a single method, can you guess which of the techniques we just learned that we'll apply? If you guessed subclass and override method, you've guessed correctly. Let's flip back to the test tree and create our new subclass, and we'll call it PatientForTesting. And it will be a subclass of Patient, and we need to make our new method on the Patient class protected. Now we can override that method on the subclass, and let's put in a constructor and a member variable for the date we want to pretend is the current system date. And let's provide a setter method for a unit test to tell the subclass what date to use for the currentDate. And now in our overridden method, we'll return that date. Now back to our test, we'll change the test to use our new subclass. And now let's use that hook to provide a date from our test scenario. I can't find that method. It needs to be public for the test to call it probably. And I forgot to change this type at the top here to be the subclass type. Now we can provide the date we want to consider the current date to be. Let's use March since February's a short month, and we'll provide a corresponding explicit date for the patient's birth date. And this should be a neonate dose since it will be under 30 days old from February to March even though it's one logical month old. And let's make our scenario name more explicit. There we go. Let's give it a try now. And it passes. At this point, we could go to town with other test scenarios where we control both the birth date and the current system date. And we could also do that with the Fitnesse test that we applied to this logic previously. So there's that problem squared away with extract getter and subclass and override method. This isn't the only way to solve this date problem. If we had CurrentDate and critical logic in other parts of the system, we could wrap the LocalDate API call with an interface and inject it at those various points. But for this situation, extract getter and subclass and override method has worked nicely.

Module Summary
In this module, we learned quite a few dependency breaking techniques. And we applied those to our untested legacy system ERServer and got quite a bit of code under test. We were able to introduce a few test doubles to replace some of those dependencies, and many of those same test doubles would also help us get higher-level tests in place should we choose to do so. For instance, we have complete control now of simulating inbound patients to the system at any part of ERServer. And we have a double to track any pages sent by any part of ERServer. Once you begin to break dependencies in legacy code, your power to get tests in place increases greatly. We applied these techniques and got code under test while doing work for our customer while adding features. So we didn't have to tell our customer to wait while we redesigned or rewrote things from scratch to be testable. We made significant progress getting a test safety net in place to help us maintain ERServer in the future. In the next module, we'll expand our bag of tricks with some techniques to help us work with hard-to-understand or tangled code.

Testing Hard to Understand Code
Module Overview
Now that we've learned some techniques to get code with difficult dependencies under test, let's tackle our next challenge. Code can be difficult to test and, therefore, risky to modify simply because it's a mess, it's hard to understand. In this module, we'll discuss some of the challenges when working with confusing, lengthy, or tangled code. Then we'll apply some basic techniques to improve the clarity of such code along with some techniques to avoid adding too much to hard-to-understand code by directing modifications to new methods or classes. Throughout this module, we'll continue improving ERServer by adding test coverage and improving the clarity of the code that we need to change to add features for our customer.

Working with Hard to Understand Code
So what kinds of things make code hard to understand? Well, there are a few common things. First is just code that's too lengthy--methods, functions, classes, or even single statements with too much going on in them. A big chunk of code is hard to look at and quickly get a feel for what it's doing and how it's doing it. Smaller chunks are easier to get a feel for with a glance. Second is just poor naming, names that presumably unintentionally obscure the intent of the code. Code is a model to solve a problem, and names are crucial to give the reader an idea of what that model is and what problem it's solving. Names of classes, methods, and variables are crucial to revealing the intent of the code. Last is a confusing division of responsibilities between code units. Again, code is a model, and if the pieces are all tangled up with multiple or mixed responsibilities, it's harder to understand the model. If a given business calculation is scattered across different units of code without a clear reason why, the intent of the code is obscured. Lengthy code often has all of these problems, and an ERServer in this module will see an excellent example of lengthy code with poor naming and tangled responsibilities. So how are we going to tackle hard-to-understand code if we can't just toss it all out and rewrite it? First, we can make very safe changes to add clarity to untested, difficult-to-understand code, just adding a comment, for example. We'll make some of these types of changes to some very confusing ERServer code in just a moment. Second, we can apply techniques that we learned in the previous module if there are dependencies preventing us from testing the code once we've begun to understand it better. That will allow more aggressive refactoring in the future. Third, if we need to modify difficult-to-understand code before we've broken dependencies and gotten tests in place, we can apply techniques to make those changes by adding new methods or classes that are tested and call those from the difficult code. We'll learn some of those techniques and apply them to ERServer in this module. Last, once tests are in place, we can refactor the code more aggressively or even rewrite portions if we have component-level tests in place. In this module, we are going to focus on improving clarity of untested code with very safe changes and also techniques to add new tested code called from the messy code. Combined with the dependency breaking techniques of the previous module, we'll have a well-rounded toolset to deal with testing legacy applications and to improve ERServer. Let's get started.

Tour of the Divergence Controller
Let's take a tour of the code we'll be working with throughout this module. This is the MainController in ERServer. Every minute, it's executing a check method on a static instance of a DivergenceController. There appears to be no output from this operation. We know from our customer that divergence is a situation when inbound patients to the emergency room are redirected to other hospitals due to the resources available to our ER, staffs and beds, being stretched too thin to effectively treat some of those inbound patients. Let's take a look at the DivergenceController class. This class has a number of instance variables. These divergence Booleans might represent whether we're currently in divergence mode for a particular priority of patients due to the colors in their names. We've already encountered red, yellow, and green priorities in our previous work. These count variables are unclear, maybe patient counts? Since we're being called in a loop in the DivergenceController from the MainController, they may be keeping state between executions. We'll have to see. These three over variables are also unclear at this point. In the constructor, the instance variables are all initialized, but the values really don't make their purpose any more clear other than our assumption about the divergence Booleans is probably accurate because they start as false. Remember, from the MainController, this instance was referenced statically, so this class is being used as a singleton. The constructor here should only be called once. Let's look at this check method that the MainController calls from its timer loop. Oh my! It looks like this one method runs from line 38 to 220. It's almost a 200-line-long method. In fact, other than this private sendDivergencePage method, check is the only method in the class. Well, at least we know one thing this class can do is send a page. But let's take a tour of the check method. So fair warning, this code is a mess. Or as the saying goes, if it's not a mess, it'll do until the mess gets here. It starts with a clump of method local variable declarations, quite a few of them. It looks like it calls back to the MainController to get a StaffAssignmentManager and an InboundPatientController. Then we have three two-element int arrays named by priority colors, not sure what these are for, and three Booleans about whether a priority has been incremented, whatever that means. Then it looks like we have some calls that go out and get data--currentInboundPatients, AvailableStaff, and AvailableBeds. Those latter two would be staff and beds not currently assigned to patients already present in the ER. Then we have some more int and int array variables. Then we start to get to some logic. We have a for loop here that loops through the available beds and increments this bedcrits method local variable each time it finds an available bed with the equipment to care for critical patients. So bedcrits appears to be a count of the subset of available beds that can care for inbound critical patients. Then it loops through the inbound patients, the patients in transit to the ER, and counts the number of inbound patients by priority. So that's the redin, yellowin, and greenin method variables. They just reflect the count of in-transit patients to our ER for each priority. Next, it loops through the available staff and puts the count of available doctors in the 0th index position of this Staff cur array, and it looks like the count of available nurses at the index 1 position. It seems a little confusing to have these counts of available staff by role in positions in an int array, but we know what it is now, so that's okay. Next, we have some logic that looks like it all has to do with beds, if the number of red inbound patients is greater than the number of beds available with critical care equipment, plus this redOver value. So redOver may be a number by which it's okay to exceed red inbound patients compared to available beds. In any case, if there're too many red inbound patients compared to available critical care beds, it looks like it increments this redCount variable and sets a Boolean to indicate that it's done so. So it looks like these color Count variables might be being incremented when a situation is detected that we might need to divert that priority of patients away from the ER. But let's keep looking. We have similar logic underneath this for needed beds versus available beds for yellow and green priority patients. But it's more complex. It looks like it may be trying to figure out if there aren't enough beds, will just diverting green inbound patients save enough beds to meet the need, or does it need to increment diversion counters for both yellow and green? Next, we have a chunk of code calculating values for a need array. And based on the conditional below it comparing need(0) to staffcur(0), it looks like the need array may be holding the needed staff based on staff role, doctor or nurse, with doc the 0 offset and nurse the 1 offset. These red, green, and yellow array values are multipliers. Let's go back to where they're declared. Each one is an array with two values again. And we know the code multiplies them by patient counts, so they probably are the needed staff for a patient with a particular priority. So a red patient needs one doctor and two nurses. Let's skip back down now. So based on what we've learned or what we think we've learned, this big conditional structure that uses the 0th index with the need and staffcur array is probably trying to figure out if diversion needs to be indicated based on needed docs versus the available docs. And the very similar block below probably doing the same thing for nurses. These incremented conditional checks look like they're attempting to only increment a given priority counter once per execution of the check method. Next, it looks like the code communicates with the external emergency transport service by URL, and this is a nasty dependency. But for each priority, if that priority had a situation, this execution, that incremented its counter, and the counter exceeds the allowedValue, and we aren't already in divergence for that priority, it sends a page and tells the transportService to divert for that priority. If we didn't increment the counter this pass, we reset that counter to 0, and if we're in divergence, we communicate with the transport service to take ourselves out of it. So this last block is revealing. The MainController is calling check every minute, and counters for each priority are incremented at most once per execution if any situation's detected where we need to divert for that priority. But it doesn't really divert for that priority until the check method has been called repeatedly with that situation still present. So that's the DivergenceController. Let's see if we can clarify this code just a little bit.

Demo: Documenting and Clarifying Code
One safe thing we can do with difficult-to-understand code is to simply reflect what we learn about the code in the code with non-functional changes. We can add spacing around clumps of code that we realize are performing a logical operation. We can add comments to those clumps describing what we've learned. And we can rename variables, methods, or classes if that helps improve the clarity of the code. As our understanding improves, our ability to see what can be tested also improves. Let's apply some of these techniques to the DivergenceController's check method. Let's do something very low risk and easy and add some comments and line spacing to reflect what we learned. So the number of available beds that have critical care equipment and can care for red inbound patients is being calculated here, inbound patients by priority here. Available staff is being determined here. Bed-based diversion logic is this clump in two parts by critical care beds and then by regular beds. Needed staff is being calculated here. And staff-based diversion logic is here, first for docs and then nurses down here. And, finally, the code clump that actually takes us into and out of divergence with our transport service and sends pages. So there we go. that's a little less hard to look at. And what we believe we learned is recorded. Let's clear up a few variable names now as well. These counts we know are for inbound patients. So let's rename them. There we go. And let's change these to availableStaff and neededStaff. And this bedcrits variable can be cleared up a little bit. And we believe these three are the required staff by priority to care for a patient. And these guys are bed overflow counts allowed by priority. And there we go. That should help. None of these changes were functional changes, but look how much easier this code is to look at and how much clearer some of the conditionals are now that we've renamed some of these variables. It's still a mess, but things are a hint better. Next, now that we know what some of these chunks do, let's see if we can separate them from this giant check method.

Demo: Extract Method
Another very safe change we can apply to untested lengthy code with good effect is extract method. This is a very common code refactoring, which almost any IDE will do for you automatically. The benefit to extracting some code from hard-to-understand code is that we both reduce the size of that source code and simultaneously provide some clarity by naming the new method. Let's give it a try on the DivergenceController. So here we are back in this lengthy check method of the DivergenceController. One of the first little code blocks we commented is this little block here that loops through the available beds and counts the number of them that are equipped to care for red priority, critical care patients. It increments this method local variable that is declared up above. That variable is first used by this code block. So let's just move it right before this block. There we go. That makes it more clear what the variable's for. Now let's ask our IDE to extract this code to a new method by selecting the code and using an IntelliJ command, and we get an Extract Method dialog window. We can name the new method, and let's call it calculateCriticalBedsAvailable. Notice the IDE already figured out pretty good names for it automatically. And the IDE also knows the list of available beds will need to be an input parameter and that it will return an integer. So let's say OK, and there we are. That line of code is now painfully clear what it's doing, and six lines in the check method body have now been replaced by a single line and without us writing any code ourselves. The IDE just did that for us automatically. Let's look at the new method it created on the DivergenceController. And that looks fine. If the DivergenceController were easily constructible, this little snippet of logic is now testable. And even if the DivergenceController isn't easily constructible, we could use the expose static method technique to test this. Maybe this little snippet of code could even move to another class in the future. There's really no downside to what we just did. And, in fact, this line of code is now so clear that the comment above it is kind of superfluous. So let's just remove it. So that was easy. Let's try this one more time. This chunk of code here that's calculating bed diversion situations looks tough. It's updating multiple method local and instance variables and will be dicier work to extract. How about this chunk here that's calculating the needed staff? It has a lot of input variables, but it looks like only one output, this neededStaff array. That may be easy to extract. Let's give it a try. Again, we'll move the variable declaration down since this code block is where it's first used, and let the IDE do the extraction. And we'll call it calculateNeededStaff. And voilà, done! There're a lot of input variables. Let's put a carriage return in here, and that's not too bad. Let's look at our new method, and that looks fine or at least no worse than it did when it was in the middle of the check method. We'll put a new line in here as well. So this doesn't look too bad. Let's pull the comment out. I'm not crazy about all these input parameters, but we can live with it for now. So that's extract method--low risk, reduce the size of our hard-to-understand and untested check method, and the method we just extracted might be individually testable if we can construct the class or make the new method static. So these are some good low-risk ways to make code more clear. But what if we need to change the code before we have tests in place? Let's learn a couple of new tricks.

Demo: Sprout Method
We've done some very safe things to improve the clarity of a hard-to-understand, untested chunk of code. But what if we need to make changes to it before we can figure out how to get tests in place? One approach is to add new tested code away from the existing messy code and call it from the old code. Sprout method does this at the method level. We add our new code in a new method and call it from a change point in the untested messy code. This technique can be used to avoid difficult dependencies as well. It isn't just for hard-to-understand code, but it does help avoid adding to an already lengthy or complex method. Let's give it a try. Here we are in the Divergence Controller again, and our customer would like us to exclude certain types of inbound patients from consideration in any divergence calculations. If it's a green priority patient and their condition value indicates that they're in a non-emergency situation and they can walk, we basically pretend like they aren't an inbound patient at all for the purposes of divergence only. First, let's see where this patient's variable is used. Looks like it's only used in this one block of code in question. So let's move it down to add a little clarity. Now we could put our logic right here in this block of code in the check method. In the case where it's a green patient that we're on in the loop, we could just not increment the green inbound counter in the case that matches the rules the customer's given us. Let's try that. So there we go. If the condition string contains ambulatory and non-emergency, we skip this entry in the loop, and the counter shouldn't get incremented. Two problems here. We can't test this unless we get the whole check method under test. And we're also making lengthy code lengthier, additional nested conditionals. What if we filtered out the patients in the list that match this case first in a separate method before we loop through and increment these counters. Let's see what that would look like. Let's go ahead and add a theoretical line of code here first just to see what it would look like. We'll reset the patients list to point to a list that only contains patients that should be included in divergence calculations. If we go this route, we may be able to test it. And it doesn't add additional complexity to the below code block. Let's implement it. So there we are. The code I used uses Java 8 streams and a filter to return all patients that either aren't green or don't have both of the keywords involved. We could rewrite this to avoid the negation logic. But this code is now in a separate testable method. Let's flip out to a test that I created for this one method, and it creates five patients, only one of which should match the conditions to be excluded, and verifies the method filters that patient out. And let's run it. And it passes. Now let's say that the DivergenceController is really hard to instantiate, and we can't make the method we sprouted static because it acts as its instance variables. Despite all of that, at least our new method isn't added to that giant pile of code in the check method, and the method name helps explain what that new little chunk of code is doing. The other thing we can do now is inline this patients variable. There we go, that's a little clearer. So that's sprout method, and it's an easy one. If we have new logic to add either to a mess or maybe to code that we just can't test yet, and we can find a way to do it at one point in that code, we can call out to a new method there to do the work from that point rather than adding to the existing code. Next, we'll look at a very similar technique that adds a new class rather than a new method.

Demo: Sprout Class
Sprout class is similar to sprout method. Rather than add to an existing hard-to-test or hard-to-understand method, we'll create a new class and call out to a method on that class. It's a particularly good fit if the code you need to add to the current method introduces a new conceptual responsibility to that existing class. Let's give it a try. Here we are in the lovely DivergenceController again at the chunk of code that determines if we need to enter or leave divergence based on the value of various instance and local method variables. A page is sent if we enter or leave divergence, and our customer would like us to add several lines of text to those pages that describe the current divergence situation. That text will always be the same regardless of whether we're entering or leaving divergence or what the type of divergence situation there is. So we could just build up a string to create the report right here adding another chunk of code. Same two problems we discussed earlier. We would be adding to the check method's mess, and if the DivergenceController class or the check method are difficult to get under test, we won't be able to easily test our new report generation either. On top of that, we're adding yet another responsibility to the DivergenceController, generating a report. What if we try the creation of a new class right at this change point? We'll call it the DivergenceReportBuilder, and we could call a method on that to return a string report. Now we could try that out as a static method. That would be fine too. It just depends on how we think that class might evolve. But let's go with a non-static buildReport method, and we'll add all of the parameters for the data that our customer wants in the report to the constructor--all the inbound patient counts, available and needed staff arrays, overall available beds, and available beds supporting critical patients. Now we'll let our IDE create the class for us. Now let's flip back to the DivergenceController, and let's also use the IDE to create our constructor for us. And let's fix all these parameter names and get them on to two lines so that it's a bit more readable. Now let's let the IDE create the method we'll call on the new class. And you can see I also filled in the constructor to populate instance variables from the constructor parameters. So we'll return null from the buildReport method for now. So I could test drive the development of this report from a unit test at this point. And normally that's what I would do. But for our purposes, we'll just paste in our implementation, and this is a pretty simple text report of the raw divergence situation data. And we'll flip over to a unit test that I've already written and run that test, and it passes. Separating this code into another class made it pretty trivial to test. And if the report changes over time, we have a class now isolated with this responsibility. Let's go back to the DivergenceController, and our new code at the change point compiles. So all that's left to do is to use this string where the code is sending divergence pages. So let's add that here on one of the pages, and we'd need to add it to all the other page lines as well. So we probably didn't save a lot of code from being added here. Creating this string was only about six lines in our new class compared to three lines here. But we avoided adding more responsibility to the check method. And we were also able to test the new logic really easily. A disadvantage of sprout class can be if the new class you create doesn't really represent a logically separate responsibility, then you're introducing a new concept to the code base that might itself be confusing. But there are many cases where this will be a good option.

Demo: Breakout Method Object
We just finished sprouting a class to add new functionality to the DivergenceController. We can also take an existing method that we need to modify and extract that method into a new class. This is the breakout method object technique. If we need to modify a method, and it's hard to get that method under test in the current class, this can be a useful technique. It may also reduce the size and number of responsibilities in the source class making that class a little easier to understand. Let's give it a try. Here we are in the DivergenceController yet again, and this time our customer would like us to make a change to the calculation of needed nurses, which is this index 1 position in the neededStaff array. If more than five nurses are needed, we can reduce the number of overall needed nurses by 1. We extracted this calculation out to a separate method earlier, but it's still in this rather large DivergenceController class. Let's try to move this calculation to a new class whose responsibility is to calculate needed staff for the inbound patients. The first thing we'll do is copy these method input parameters. We're going to make these instance variables on the new class. And we'll create a new class, and let's call it the NeededStaffCalculator. And we'll paste these method parameters into it and turn them into instance variables. Then we can rely on our IDE to generate a constructor for us. And let's add some spacing in here. And there's our constructor. Now, let's declare a method that will perform our calculation. Let's try overall as the name since we already have neededStaff in the class name. And it will return an int array that specifies needed docs and nurses for all inbound patients of all priorities. I'm guessing a bit with this method name that in the future, we might also ask the class for just needed nurses or just needed docs or maybe just needed staff for a particular priority of inbound patients. In any case, let's go ahead and return to the DivergenceController, and we'll copy our target method body out and paste it into our new method in our new class. And that compiles. Now if this method had referenced instance variables of the DivergenceController or called other methods on the DivergenceController, we'd have compile errors now, and we'd have to figure out a way to deal with those references at this point. For instance variable references, we could add those as parameters to either the constructor or our new method. For calls to other methods, we might have to pass an instance of the DivergenceController itself in as a parameter, which is a little weird, or extract an interface for the DivergenceController and pass it in as that interface. Both of those are a little ugly, but if, overall, moving the method out to this class helps split responsibilities better or helped us test the logic much more easily, it still might be an overall win. But we don't have either of those issues here. We did get a duplicate code warning, but that's just because we haven't deleted the old method body in the DivergenceController that we copied from. Let's create a unit test for our new class. Here we are. So this is a very simple scenario to test. We just provide some number of inbound patients for each priority color and the multipliers for docs and nurses to use. So in this scenario, we should get 4 needed docs and 8 nurses. Let's run it, and it passes. Now let's make the requested feature change in our new class. Here as the last part of the calculation, if we ended up with more than 5 nurses needed overall, that's the sub 1 element, we'll just subtract 1 from it and store the new value back into that element. There we go. Now let's flip back and run our test, and it fails because we're still expecting the old value of 8 nurses, and we're getting 7 back. So, really, we need two scenarios tested at a minimum here. One where the scenario calls for 5 or fewer nurses and one where more than 5 is called for. Let's just go ahead and create the second scenario now, and we'll make this the over-5 case and change the inbounds on the first scenario so it will result in fewer than 5 nurses. Change our expectation to 7 in the second case. And, let's see, in the first case, the red patient would need 2 nurses, and the yellow page 1 and the green 1, so we'll change the expectation to 4. Now let's run both these tests, and they both pass. Since we have a boundary condition when there're 5 nurses, I might add a third scenario where the needed nurses comes out to exactly 5. But for now, let's return to the DivergenceController and use our new class. We'll delete the old method, and that gives us a compile error. Let's jump up to where that error is. And here we'll replace the call to the old method with a call to our new class, with the old method parameters now being constructor parameters, and add the call to the overall method. There we go. That's breakout method object. Now there are still a number of things that seem awkward here. This two-element array with the magic 0 and 1 positions for docs and nurses is kind of rough. It's not immediately apparent what those indexes are, and it seems like they might be easy to mix up and introduce a bug. Now that we have a class responsible for this calculation, maybe we could add methods to it asking for just docs or nurses instead of overall needed staff and just sum those into a variable here in the DivergenceController. With the tested class responsible for just this staff calculation, we could be a little braver about those kinds of changes. Maybe these required staff multipliers declared here at the top of the check method could also be owned by our NeededStaffCalculator. So how does the DivergenceController overall look now after our work in these last few clips? We've moved some logic like critical bed calculation out to other methods. We've renamed a number of variables to indicate their purpose more clearly. And we've moved some existing code and some new logic out to other classes entirely. The check method is, overall, about the same size, but we did add a lot of whitespace and comments to it, as well as add some functionality. If we could figure out how to extract the bed-related divergence calculations and the staff-related divergence calculations out to separate classes, things might really start to get easy to understand and test. We'll discuss that a bit in the next module.

Module Summary
In this module, we made the ERServer DivergenceController a little more clear by grouping, commenting, and renaming elements in the code and by extracting groups of lines performing a logical operation to separate methods, and by breaking out a method to a new class. We added new tested code called by the DivergenceController using sprout method and sprout class. Throughout this work, we were able to add functionality that the customer needed while gradually improving the understandability of the DivergenceController. In the next module, we'll wrap things up by reviewing our progress and discussing ways to further improve our skills and our legacy code base.

Expanding Your Skills
Module Overview
We did quite a bit of work on our legacy system in the previous modules learning techniques to get code under test as we went. Is there more we can learn that will help us work with legacy code bases? Of course there is. In this module, we'll summarize our progress and accomplishments on ERServer. And we'll discuss some code in the application that still needs some work. And we'll provide a good way to practice our new skills. Finally, we'll discuss some additional materials that can provide us with even more skills to apply when working with legacy systems.

Our Accomplishments with ERServer
So what did we accomplish in this course as we worked on ERServer? Well, first and foremost, we added new functionality to the system at our customer's request. We did not say at any point that this code is crappy and untestable and, therefore, needs at least parts of it redesigned and rewritten before we can work on it. However, as we did that work, we broke dependencies to allow us to get some characterization tests in place before we modified code. We created abstractions for some of those dependencies through interfaces. And we applied techniques to create seams where test doubles for those dependencies could be provided. This incremental work resulted in the beginnings of a safety net of unit tests for ERServer. Zero percent of the code was covered by unit tests for ERServer when we began work. Now, there is about 25% line test coverage. And the dependency breaking we did will allow us to expand that in the future. We can have more confidence when working on ERServer due to these tests. Last, even for code we couldn't quickly or easily test, we improved the understandability and, thus, the maintainability of that code. In a few cases, we were able to avoid significant changes to hard-to-understand code and, instead, add functionality by calling out to new tested code. Another potential future benefit of our work is the possibility of adding higher-level tests now that the code is more testable. We can expose critical business logic to customers and domain experts with these higher-level tests. Consider the core features of ERServer that we saw in this course. There was situational alerting--pages sent when important events regarding inbound patients occur. We saw some very complex divergence logic--crucial logic determining when our ambulance and transport services are asked to divert patients to other hospitals. And we saw essential resource management logic to track staff and beds both available and already assigned to patients. This kind of core business logic is great territory for tools like Fitnesse or Cucumber that can expose that logic to customers, as well as act as additional regression test safety nets to unit tests. But how could we be ready for that? We just started getting unit tests in place on a completely untested system. Well, the dependencies we broke and the abstractions via interfaces and test doubles we created can be applied to higher-level tests just as they can to unit tests. We created abstractions for inbound patients, for the source of staff, for the source of beds, and for the transmission of alerts. Situational alerting could now be covered by higher-level tests by using those abstractions. The same with resource management. Customer-facing, high-level tests for that just need these test doubles, which we already provided for the unit tests. Divergence logic needs all of these abstractions as well, in addition to one that we didn't create during the course. We'll touch on that in a moment. The work we did to allow unit tests paves the way for higher-level, customer-facing tests on business scenarios and even for a fully deployed instance of ERServer that's connected only to test doubles allowing for full system simulations. With just the little bit of work we did during this course, much of the code went from difficult to test to being very testable at multiple levels of granularity.

Practicing on the Divergence Controller
There's still plenty of opportunity to build on what we've learned in this course, and ERServer still has some untested code and issues that we can practice on. As mentioned earlier, ERServer is on GitHub at the URL shown. There are two branches. Main is the branch that we used as our starting point for this course, so the work we did during the course isn't reflected there, and it's still completely untested. The aftercourse branch contains all the work we did in the course. So if you want to pick up from where we left off, that's the branch to start from. A class we didn't break dependencies for is the divergence controller, and that's a good one to practice on even if starting from the aftercourse branch where some of the abstractions for its dependencies exist already but still would need to be injected somehow to the controller. The divergence controller has hard, concrete dependencies on the inbound patient controller, the staff assignment manager from which it gets both available beds and available staff, the emergency response service, which it sends divergence start and end notifications to, and the vendor pager system, which it uses to send pages about divergence to staff. For the inbound patient controller, you can use the inbound patient source interface. For the staff assignment manager, it can be injected as is but with test doubles for its bed provider and staff provider in turn injected into it. Or you could extract a new interface for just the methods that the divergence controller calls on the staff assignment manager. The emergency transport service would need a new interface extracted, and the divergence controller only uses the divergence methods on that service. So you could create an abstraction called a divergence system and inject that as a test double when testing. For the vendor paging system, we could use the alert transmitter interface that was created during the course. Using the techniques we learned to provide test doubles for these dependencies will allow you to get a few unit test scenarios in place for the divergence controller. If there aren't enough beds for the inbound patients, for example, and the check method is called repeatedly in that situation until the allowed count is exceeded, does the convergence controller go in to the expected type of divergence? Once you have at least a few tests in place, you can be a little braver with refactorings to the divergence controller. So what kind of changes might you attempt to improve the clarity of the divergence controller once you have at least a few tests in place for it? Well, you could apply the extract method technique to try to move more code out of the check method body. You could even create new classes to handle some of that logic using the breakout method object technique. The staff-related and bed-related divergence calculations are good candidates for that. Once extracted, such code can be tested more thoroughly with unit tests on that specific method or new class. The divergence controller may become more like a mediator or coordinating class where most of the actual work is done in other classes that have their own test that the divergence controller calls. Tests on the divergence controller itself become more like higher-level component tests rather than unit tests. And these divergence controller tests could even be moved away from JUnit into a customer-facing testing tool like Fitness. Once those hard dependencies are broken, opportunity abounds.

Additional Resources and Summary
In addition to practicing skills learned in this course, there are some great resources to expand your skills working with legacy code bases to get them tested and more clear. A primary source is Working Effectively with Legacy Code by Michael Feathers, which includes techniques we covered in this course along with many others. The examples are in Java but most easily apply to any object-oriented language. Clean Code by Bob Martin has lots of valuable tips, guidance, and patterns to make code more understandable. And the Refactoring book by Martin Fowler is crucial source material. Every IDE-assisted refactoring we performed in this course originated from this work. Also, here on Pluralsight, if you're relatively new to unit testing, Introduction to Testing in Java by Richard Warburton is a very helpful course and includes more coverage of test doubles and dependency injection. Clean Code: Writing Code for Humans by Cory House can help you make a legacy code base more readable and maintainable. I hope you enjoyed this journey. Our legacy application now has tests and is better prepared for further tests in the future, all done without making risky changes, but through conservative techniques, to gradually get code under test as we needed to make feature changes to the code. Hopefully the techniques you learned in this course will help you to get difficult, untested code that you encounter in the future into better, testable, more maintainable states. Thanks for sticking with me for Unit Testing Legacy Code in Java.